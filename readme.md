# Bacon Challenge

This repo provides a tool for calculating the degrees of separation between any two actors, inspired by [Bacon Numbers](https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon#Bacon_numbers), based on the [Movie Dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset). It also provides a basic HTTP API for fetching degrees of separation, as well as adding new movies to the data.

## Prerequisites

All of the code is in Python 3, written and tested with 3.9.1. The following non-standard Python libraries are required for various pieces of this repo, all of which can be installed via the requirements file:

* flask
* pytest
* requests

```
python -m pip install -r requirements.txt
```

## Summary

Once the prerequisites are met, the various scripts and their purposes are:

* parse_movies.py - provides functions for parsing the dataset into a form useable by query_degrees.py (only credits.csv from the Movies Database is currently supported)
* query_degrees.py - provides methods for processing the graphs generated by parse_movies.py
* server.py - an HTTP server which hosts an API that uses the above tools to calculate and return actor degrees of separation
* client.py - a basic script which accepts root and target actors via user or file input and queries the server for results
* test_*.py - tests, intended to be run via pytest

## Usage

The typical usage, from scratch, is:

1. Download the [Movie Dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset). Once extracted, you'll need the credits.csv file for the next step.

2. Preprocess credits.csv by running (modify paths as necessary):

```
python -m graph.parse_movies credits.csv
```

This will output an actors.jsonl file which will be consumed later. It should take less than a minute, and prints progress updates.

3. Run the server:

```
python -m server.server
```

This will take ~10-15 seconds to start up while it builds a graph from the preprocessed data - an unfortunate startup time, but the server is long-lived and an easy improvement would be to persist the graphs to another file.

Note that your terminal/prompt/etc. will block while the server runs using the above command, so you'll need a separate one for the client.

4. Run the client:

```
python -m client.client

or

python -m client.client -f client/client_example.data
```

Without an input file, the client will repeatedly prompt the user for two actors to determine the degree of separation between. It will ask the server and print the response.

With an input file, the client will send all requests defined in the file and then return without waiting for input. See client_example.data for the structure of the data and an example request of each type. Requests which add new movies/actors will be persisted across server runs.

5. Run the tests (they also expect preprocessing to be done):

```
pytest.exe
```

pytest may not be directly accessible by default, depending on your install settings. The tests include some slow/degenerate cases in addition to constructing the entire graph, and can take up to ~30 seconds to run as a result.

In addition to the output of pytest, a results file will be generated in a test_results folder. This is a csv showing how long it took to determine the degree of separation of each pair of actors in the degree tests.

Some of the above (notably, running the server) will create a server log that you can read to verify the requests that were run (including some metadata).

## Improvements

Here's a non-exhaustive list of improvements that could be made.

* As mentioned above, persisting the graphs to files would significantly speed up initialization, at the cost of a little more preprocessing.
* All comparisons are case-sensitive. You should be able to search for "kevin bacon", or "kEvIn BaCoN", if that's your fancy. Simple solution is to lower-case everything, but you'd quickly run into issues with non-ASCII names doing it naively.
* The poor cases - degree 4+ - can take a long time and provide no feedback. This is about usability. There will always be pathological cases, and we shouldn't just stall without notifying the user for several seconds.
* No metadata. We can fetch degrees of separation, but a user might care about some of the 'trivia' surrounding connections:
  * which movies and actors connect two actors
  * given the above, the ability to see alternate connection paths
  * ask how two actors are connected through a third one - e.g. Kevin Bacon and Billy Boyd have a degree of 2, but is there a chain - perhaps of greater degree - that links them via George Clooney or Humphrey Bogart in particular?

## Focus Areas

Here, I highlight what I focused on explicitly:

### Testing and Robustness

In addition to the pytest tests which cover most of the obvious base cases as well as bugs and issues found during development for each of the primary modules (parsing, searching, server), the client allows some more realistic testing from the perspective of a user or other service (via the input file). I verify that everything works, from scratch via a fresh checkout, on both Windows 10 and Ubuntu 20.04 LTS (via the Windows Subsystem for Linux) by following just this readme. The search tests provide basic timing functionality to verify the performance of the search algorithm, and the server provides logging (including datestamp, PID, TID, and unique request IDs) for debugging and verification.

### Usability

The ability to quickly and easily check out the repo and get things working via the readme with no obstacles is important - that first impression is vital for new consumers. The requirements file provides a smooth way for fresh checkouts to get up and running (with fixed versions to minimize the chance of breakage). Additionally, the client provides an easy interface for doing your own manual tests or for writing integration tests via the input file, and could theoretically be provided to an end-user in its current state. In practice, a target user who would use the client rather than integrating with the API should be provided with a friendlier interface like a GUI or web app.

The HTTP API returns detailed enough error information for the client to easily determine what went wrong and why in most cases, as well as some basic documentation at the root to get started. That's not a substitute for real docs, though - actual API documentation would be a prerequisite for shipping this project.
